wandb: Currently logged in as: stonehenge0 (stonehenge0-university-of-goettingen) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
Traceback (most recent call last):
  File "/scratch-scc/users/u14374/bachelorarbeit/bachelorthesis_multilingual_steering/src/multijail_dev.py", line 292, in <module>
    main()
  File "/scratch-scc/users/u14374/bachelorarbeit/bachelorthesis_multilingual_steering/src/multijail_dev.py", line 288, in main
    run_and_save(config)
  File "/scratch-scc/users/u14374/bachelorarbeit/bachelorthesis_multilingual_steering/src/multijail_dev.py", line 261, in run_and_save
    raise RuntimeError(f"Error running command for {config.run_name}:\n{out.stderr}\n Returncode:{out.returncode}")
RuntimeError: Error running command for test_run_meta-llama/meta-llama-3-8b-instruct_global_mmlu_L12_S0.1:
WARNING:root:Argument requires 4 integers or None, separated by ','. Missing values will be filled with defaults.
wandb: Currently logged in as: stonehenge0 (stonehenge0-university-of-goettingen) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.0
wandb: Run data is saved locally in /scratch-scc/users/u14374/bachelorarbeit/bachelorthesis_multilingual_steering/src/wandb/run-20250804_172524-d92906z1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-forest-84
wandb: ‚≠êÔ∏è View project at https://wandb.ai/stonehenge0-university-of-goettingen/bachelorarbeit
wandb: üöÄ View run at https://wandb.ai/stonehenge0-university-of-goettingen/bachelorarbeit/runs/d92906z1
WARNING:lm_eval.__main__: --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
INFO:lm_eval.__main__:Selected Tasks: ['global_mmlu_bn', 'global_mmlu_de', 'global_mmlu_en', 'global_mmlu_zh']
WARNING:lm_eval.evaluator:Model appears to be an instruct variant but chat template is not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
INFO:lm_eval.evaluator:Setting random seed to 1234 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
INFO:lm_eval.evaluator:Initializing steered model, with arguments: {'pretrained': 'meta-llama/meta-llama-3-8b-instruct', 'steer_path': '/scratch1/users/u14374/bachelorarbeit/bachelorthesis_multilingual_steering/tmp/2025-08-04 17:19:16.770720'}
WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
INFO:lm_eval.models.huggingface:Using device 'cuda:0'
INFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:07<00:21,  7.28s/it]
Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:19<00:20, 10.45s/it]
Loading checkpoint shards:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:32<00:11, 11.41s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:34<00:00,  7.65s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:34<00:00,  8.60s/it]
Traceback (most recent call last):
  File "/mnt/vast-standard/home/stein65/u14374/miniforge3/envs/modified_lm_eval_env/bin/lm_eval", line 8, in <module>
    sys.exit(cli_evaluate())
  File "/scratch-scc/users/u14374/bachelorarbeit/bachelorthesis_multilingual_steering/src/modified_llm_eval_harness/lm_eval/__main__.py", line 450, in cli_evaluate
    results = evaluator.simple_evaluate(
  File "/scratch-scc/users/u14374/bachelorarbeit/bachelorthesis_multilingual_steering/src/modified_llm_eval_harness/lm_eval/utils.py", line 439, in _wrapper
    return fn(*args, **kwargs)
  File "/scratch-scc/users/u14374/bachelorarbeit/bachelorthesis_multilingual_steering/src/modified_llm_eval_harness/lm_eval/evaluator.py", line 231, in simple_evaluate
    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(
  File "/scratch-scc/users/u14374/bachelorarbeit/bachelorthesis_multilingual_steering/src/modified_llm_eval_harness/lm_eval/api/model.py", line 155, in create_from_arg_string
    return cls(**args, **args2)
  File "/scratch-scc/users/u14374/bachelorarbeit/bachelorthesis_multilingual_steering/src/modified_llm_eval_harness/lm_eval/models/hf_steered.py", line 103, in __init__
    raise ValueError(f"Unknown steer file type: {steer_path}")
ValueError: Unknown steer file type: /scratch1/users/u14374/bachelorarbeit/bachelorthesis_multilingual_steering/tmp/2025-08-04 17:19:16.770720

 Returncode:1
