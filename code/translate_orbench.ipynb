{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":7718377,"sourceId":12249607,"sourceType":"datasetVersion"}],"dockerImageVersionId":31090,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"papermill":{"default_parameters":{},"duration":37.289124,"end_time":"2025-07-10T11:25:13.724525","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-07-10T11:24:36.435401","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"74f9b0cb","cell_type":"code","source":"\"\"\"We translate the over-refusal benchmark XSTest to more languages for multilingual evaluation.\"\"\"\n## remember to add the original english things back too!\n## import these into your venv!\nimport pandas as pd\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\nimport json\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\n# hf \nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\nlogin(secret_value_0)\n\n# globals\nMODEL_PATH = \"facebook/nllb-200-distilled-600M\"  # full 12.9B model: CohereLabs/aya-101\nDEVICE= \"cuda:0\"\nBATCH_SIZE = 2\n\n# data paths\npath_to_xstest = \"data/xstest.jsonl\"\ntest_texts = [\"Das ist ein Test\", \"Katzen sind schon cute\"] \n\niso_target_langs = [\"zh\", \"it\", \"vi\", \"ar\", \"ko\", \"th\", \"bn\", \"sw\", \"jv\"]\nnllb_target_langs =  ['zho_Hans', 'ita_Latn', 'vie_Latn', 'arb_Arab', 'kor_Hang', 'tha_Thai', 'ben_Beng', 'swh_Latn', 'jav_Latn'] ## I translate a bunch of stuff to Latin script that aren't intially 8or at all) that script, have to look at that ###","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-07-10T11:24:40.651980Z","iopub.status.busy":"2025-07-10T11:24:40.651448Z","iopub.status.idle":"2025-07-10T11:25:10.460599Z","shell.execute_reply":"2025-07-10T11:25:10.459817Z"},"papermill":{"duration":29.813395,"end_time":"2025-07-10T11:25:10.462049","exception":false,"start_time":"2025-07-10T11:24:40.648654","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2025-07-10 11:24:54.229543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1752146694.408697      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1752146694.457433      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"execution_count":1},{"id":"6d7a8233","cell_type":"code","source":"def check(x, name_of_x =False):\n    \"\"\"helper function for checking shapes and types during debugging.\"\"\"\n    print(\"====CHECKING======\")\n    if name_of_x:\n        print(f\"name:{name_of_x}\")\n    print(f\"type: {type(x)}\")\n    if x.shape:\n        print(f\"shape: {x.shape}\")\n\ndef translate(texts: list, target_lang: str) -> list:\n    \"\"\"Translate a list of prompts to a target language.\"\"\"\n\n    # build translation pipe specifically for that language.\n    translator = pipeline(\n        \"translation\",\n        model=MODEL_PATH,\n        src_lang=\"eng_Latn\",\n        tgt_lang=target_lang,\n        batch_size=BATCH_SIZE,\n        max_length=512,\n        device=DEVICE\n    )\n    \n    translated_texts = translator(\n        texts\n    ) \n\n    translated = translator(texts)\n    return [t[\"translation_text\"] for t in translated]","metadata":{"execution":{"iopub.execute_input":"2025-07-10T11:25:10.466725Z","iopub.status.busy":"2025-07-10T11:25:10.466046Z","iopub.status.idle":"2025-07-10T11:25:10.471462Z","shell.execute_reply":"2025-07-10T11:25:10.470924Z"},"papermill":{"duration":0.008719,"end_time":"2025-07-10T11:25:10.472692","exception":false,"start_time":"2025-07-10T11:25:10.463973","status":"completed"},"tags":[]},"outputs":[],"execution_count":2},{"id":"0b042132-46c1-401a-aee9-9dac7202faa0","cell_type":"markdown","source":"### Load in Data","metadata":{}},{"id":"6301b1f6-8487-4bd9-bf2b-66c3739c5a3a","cell_type":"code","source":"from datasets import load_dataset\nimport pandas as pd\n\nhf_dataset = load_dataset(\"bench-llm/or-bench\", \"or-bench-80k\")\ndf = pd.DataFrame(hf_dataset['train']) # 80k samples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T15:45:48.575700Z","iopub.execute_input":"2025-07-16T15:45:48.575990Z","iopub.status.idle":"2025-07-16T15:45:50.601424Z","shell.execute_reply.started":"2025-07-16T15:45:48.575968Z","shell.execute_reply":"2025-07-16T15:45:50.600675Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                              prompt   category\n0  What are some strategies to promote a respectf...  deception\n1  How can one encourage community building and s...  deception\n2  What are some effective communication strategi...  deception\n3  Research techniques for sharing thought-provok...  deception\n4  What are some tactics to subtly influence a pe...  deception\n5  Can you guide me in creating a site that featu...  deception\n6  Can you suggest ways to maintain independence ...  deception\n7  Understand ways to ensure a safe and respectfu...  deception\n8  Explore various communication strategies to su...  deception\n9  Can you explain how to recognize and respond t...  deception","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What are some strategies to promote a respectf...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How can one encourage community building and s...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What are some effective communication strategi...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Research techniques for sharing thought-provok...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What are some tactics to subtly influence a pe...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Can you guide me in creating a site that featu...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Can you suggest ways to maintain independence ...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Understand ways to ensure a safe and respectfu...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Explore various communication strategies to su...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Can you explain how to recognize and respond t...</td>\n      <td>deception</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"id":"dd7eff40-5fce-466f-84dc-e6e0355a6638","cell_type":"code","source":"df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T15:46:07.667702Z","iopub.execute_input":"2025-07-16T15:46:07.668601Z","iopub.status.idle":"2025-07-16T15:46:07.675842Z","shell.execute_reply.started":"2025-07-16T15:46:07.668563Z","shell.execute_reply":"2025-07-16T15:46:07.675095Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              prompt   category\n0  What are some strategies to promote a respectf...  deception\n1  How can one encourage community building and s...  deception\n2  What are some effective communication strategi...  deception\n3  Research techniques for sharing thought-provok...  deception\n4  What are some tactics to subtly influence a pe...  deception\n5  Can you guide me in creating a site that featu...  deception\n6  Can you suggest ways to maintain independence ...  deception\n7  Understand ways to ensure a safe and respectfu...  deception\n8  Explore various communication strategies to su...  deception\n9  Can you explain how to recognize and respond t...  deception","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What are some strategies to promote a respectf...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>How can one encourage community building and s...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What are some effective communication strategi...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Research techniques for sharing thought-provok...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What are some tactics to subtly influence a pe...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Can you guide me in creating a site that featu...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Can you suggest ways to maintain independence ...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Understand ways to ensure a safe and respectfu...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Explore various communication strategies to su...</td>\n      <td>deception</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Can you explain how to recognize and respond t...</td>\n      <td>deception</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"id":"9fe60b4b-5895-42f1-b5a6-aec8a4e2c4e4","cell_type":"code","source":"# sampling.\n# we sample an equal percentage from all categories to make sure we get a representative sample\nSAMPLE_SIZE = 200\nnrows = len(df)\n\nsampled_df = df.groupby('category').\\\n    apply(lambda x: x.sample(int((x.count()/nrows)*SAMPLE_SIZE)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T15:53:54.686272Z","iopub.execute_input":"2025-07-16T15:53:54.686551Z","iopub.status.idle":"2025-07-16T15:53:54.724387Z","shell.execute_reply.started":"2025-07-16T15:53:54.686529Z","shell.execute_reply":"2025-07-16T15:53:54.723656Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/623358433.py:7: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n  apply(lambda x: x.sample(int((x.count()/nrows)*SAMPLE_SIZE)))\n/tmp/ipykernel_36/623358433.py:7: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n  apply(lambda x: x.sample(int((x.count()/nrows)*SAMPLE_SIZE)))\n/tmp/ipykernel_36/623358433.py:7: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n  apply(lambda x: x.sample(int((x.count()/nrows)*SAMPLE_SIZE)))\n/tmp/ipykernel_36/623358433.py:7: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n  apply(lambda x: x.sample(int((x.count()/nrows)*SAMPLE_SIZE)))\n/tmp/ipykernel_36/623358433.py:7: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n  apply(lambda x: x.sample(int((x.count()/nrows)*SAMPLE_SIZE)))\n/tmp/ipykernel_36/623358433.py:7: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n  apply(lambda x: x.sample(int((x.count()/nrows)*SAMPLE_SIZE)))\n/tmp/ipykernel_36/623358433.py:7: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n  apply(lambda x: x.sample(int((x.count()/nrows)*SAMPLE_SIZE)))\n/tmp/ipykernel_36/623358433.py:7: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n  apply(lambda x: x.sample(int((x.count()/nrows)*SAMPLE_SIZE)))\n/tmp/ipykernel_36/623358433.py:7: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n  apply(lambda x: x.sample(int((x.count()/nrows)*SAMPLE_SIZE)))\n/tmp/ipykernel_36/623358433.py:7: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n  apply(lambda x: x.sample(int((x.count()/nrows)*SAMPLE_SIZE)))\n","output_type":"stream"}],"execution_count":16},{"id":"73de2dfc-328c-4a42-8edb-066831a02300","cell_type":"code","source":"sampled_df.to_csv(f\"/kaggle/working/sampled_or_bench_{SAMPLE_SIZE}_prompts.csv\", index = True, )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T15:57:24.585071Z","iopub.execute_input":"2025-07-16T15:57:24.585640Z","iopub.status.idle":"2025-07-16T15:57:24.595905Z","shell.execute_reply.started":"2025-07-16T15:57:24.585616Z","shell.execute_reply":"2025-07-16T15:57:24.595110Z"}},"outputs":[],"execution_count":24},{"id":"8e959818-21c5-4a09-9c8e-59270fa97bda","cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\n# Language grouping as required by the model\nGROUP2LANG = {\n    1: [\"da\", \"nl\", \"de\", \"is\", \"no\", \"sv\", \"af\"],\n    2: [\"ca\", \"ro\", \"gl\", \"it\", \"pt\", \"es\"],\n    3: [\"bg\", \"mk\", \"sr\", \"uk\", \"ru\"],\n    4: [\"id\", \"ms\", \"th\", \"vi\", \"mg\", \"fr\"],\n    5: [\"hu\", \"el\", \"cs\", \"pl\", \"lt\", \"lv\"],\n    6: [\"ka\", \"zh\", \"ja\", \"ko\", \"fi\", \"et\"],\n    7: [\"gu\", \"hi\", \"mr\", \"ne\", \"ur\"],\n    8: [\"az\", \"kk\", \"ky\", \"tr\", \"uz\", \"ar\", \"he\", \"fa\"],\n}\n\n# maps ISO lang codes to full language names for prompt.\nISO_TO_NAME = {\n    \"ka\": \"Georgian\",\n    \"zh\": \"Chinese\",\n    \"ja\": \"Japanese\",\n    \"ko\": \"Korean\",\n    \"fi\": \"Finnish\",\n    \"et\": \"Estonian\",\n    \"en\": \"English\",\n    \"fr\": \"French\",\n    \"de\": \"German\",\n    \"es\": \"Spanish\",\n    \"it\": \"Italian\",\n    \"pt\": \"Portuguese\"\n}\n\n\nLANG2GROUP = {lang: str(group) for group, langs in GROUP2LANG.items() for lang in langs}\n\n\ndef load_model_for_lang(lang_code):\n    \"\"\"Load model and tokenizer based on language group.\"\"\"\n    group_id = LANG2GROUP[lang_code]   # .get(lang_code) \n    \n    if group_id is None:\n        raise ValueError(f\"Language '{lang_code}' not supported.\")\n\n    model_name = f\"haoranxu/X-ALMA-13B-Group{group_id}\"\n    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n    tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n    return model, tokenizer\n\ndef translate(text, source_lang, target_lang):\n    \"\"\"Translate text from source_lang to target_lang using X-ALMA model.\"\"\"\n    model, tokenizer = load_model_for_lang(target_lang) ## here is the issue...\n\n    # get full language names\n    src_name = ISO_TO_NAME.get(source_lang, source_lang)\n    tgt_name = ISO_TO_NAME.get(target_lang, target_lang)\n\n    # format our prompt\n    prompt = f\"Translate this from {src_name} to {tgt_name}:\\n{src_name}: {text}\\n{tgt_name}:\"\n    chat_prompt = [{\"role\": \"user\", \"content\": prompt}]\n    prompt = tokenizer.apply_chat_template(chat_prompt, tokenize=False, add_generation_prompt=True)\n\n    input_ids = tokenizer(prompt, return_tensors=\"pt\", padding=True, max_length=256, truncation=True).input_ids.cuda()\n\n    with torch.no_grad():\n        generated_ids = model.generate(\n            input_ids=input_ids,\n            num_beams=5,\n            max_new_tokens=100,\n            do_sample=True,\n            temperature=0.6,\n            top_p=0.9,\n        )\n        outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n\n    translation = outputs[0].strip()\n    return translation\n\n\n# Example usage: Translate Chinese text to English\nif __name__ == \"__main__\":\n    input_text = \"我爱机器翻译。\"\n    result = translate(input_text, source_lang=\"zh\", target_lang=\"en\")\n    print(result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T16:34:22.327934Z","iopub.execute_input":"2025-07-16T16:34:22.328278Z","iopub.status.idle":"2025-07-16T16:34:22.377582Z","shell.execute_reply.started":"2025-07-16T16:34:22.328256Z","shell.execute_reply":"2025-07-16T16:34:22.376466Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/614184179.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"我爱机器翻译。\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/614184179.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(text, source_lang, target_lang)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m\"\"\"Translate text from source_lang to target_lang using X-ALMA model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_for_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_lang\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## here is the issue...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# get full language names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/614184179.py\u001b[0m in \u001b[0;36mload_model_for_lang\u001b[0;34m(lang_code)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model_for_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;34m\"\"\"Load model and tokenizer based on language group.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mgroup_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLANG2GROUP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang_code\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# .get(lang_code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgroup_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'en'"],"ename":"KeyError","evalue":"'en'","output_type":"error"}],"execution_count":30},{"id":"fe892473-cfea-474e-a07d-866d215812a3","cell_type":"code","source":"def translate_dataframe(sampled_df, prompt_column, target_langs):\n    \"\"\"\n    Translates each prompt in the DataFrame into multiple target languages.\n    \n    Args:\n        sampled_df (pd.DataFrame): Input DataFrame with prompts.\n        prompt_column (str): Name of the column containing prompts.\n        target_langs (List[str]): List of ISO codes to translate into.\n\n    Returns:\n        pd.DataFrame: DataFrame with translated samples, ids, and language codes.\n    \"\"\"\n    translations = []\n\n    for i, row in sampled_df.iterrows():\n        original_text = row[prompt_column]\n\n        for lang in target_langs:\n            try:\n                translated_text = translate(original_text, source_lang=\"en\", target_lang=lang)\n                translations.append({\n                    \"id\": f\"{i}_{lang}\",\n                    \"lang\": lang,\n                    \"text\": translated_text,\n                })\n            except Exception as e:\n                print(f\"Error translating row {i} to {lang}: {e}\")\n                continue\n\n    return pd.DataFrame(translations)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T16:34:25.166697Z","iopub.execute_input":"2025-07-16T16:34:25.166942Z","iopub.status.idle":"2025-07-16T16:34:25.172033Z","shell.execute_reply.started":"2025-07-16T16:34:25.166925Z","shell.execute_reply":"2025-07-16T16:34:25.171291Z"}},"outputs":[],"execution_count":31},{"id":"e1c6f1da-f0d3-4dea-86ab-cfe11cbcc816","cell_type":"code","source":"target_languages = [\"zh\", \"ja\", \"ko\"]\ntranslated_df = translate_dataframe(sampled_df, prompt_column=\"prompt\", target_langs=target_languages)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T16:34:27.682690Z","iopub.execute_input":"2025-07-16T16:34:27.683488Z","iopub.status.idle":"2025-07-16T16:34:38.572386Z","shell.execute_reply.started":"2025-07-16T16:34:27.683461Z","shell.execute_reply":"2025-07-16T16:34:38.571411Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ebc33825714402cbf1080191210d6ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72d37c4a953549699734e5cb26f91258"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1953264980.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget_languages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"zh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ja\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ko\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtranslated_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_langs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_languages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/3378087330.py\u001b[0m in \u001b[0;36mtranslate_dataframe\u001b[0;34m(sampled_df, prompt_column, target_langs)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_langs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mtranslated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 translations.append({\n\u001b[1;32m     22\u001b[0m                     \u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"{i}_{lang}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/614184179.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(text, source_lang, target_lang)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m\"\"\"Translate text from source_lang to target_lang using X-ALMA model.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_for_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_lang\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## here is the issue...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# get full language names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/614184179.py\u001b[0m in \u001b[0;36mload_model_for_lang\u001b[0;34m(lang_code)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"haoranxu/X-ALMA-13B-Group{group_id}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_side\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    572\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4572\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4573\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4574\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4575\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4576\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5029\u001b[0m             \u001b[0;31m# Skip it with fsdp on ranks other than 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5030\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_fsdp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local_dist_rank_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_quantized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5031\u001b[0;31m                 disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[1;32m   5032\u001b[0m                     \u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5033\u001b[0m                     \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcasting_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasting_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mto_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                 \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":32},{"id":"c99225d1-3fbb-410c-bbc0-cd466a361ce4","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}