{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-22T20:31:03.369388Z",
     "iopub.status.busy": "2025-06-22T20:31:03.369062Z",
     "iopub.status.idle": "2025-06-22T20:31:03.373524Z",
     "shell.execute_reply": "2025-06-22T20:31:03.372718Z",
     "shell.execute_reply.started": "2025-06-22T20:31:03.369368Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"We translate the over-refusal benchmark XSTest to four more languages and evaluate a steered and an unsteered model on the benchmark.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:31:08.910714Z",
     "iopub.status.busy": "2025-06-22T20:31:08.910113Z",
     "iopub.status.idle": "2025-06-22T20:32:33.768291Z",
     "shell.execute_reply": "2025-06-22T20:32:33.767647Z",
     "shell.execute_reply.started": "2025-06-22T20:31:08.910691Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6780bea42314f9b9daae2981b8f7766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/808 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b739edd4bbe4865914972e8ff907463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84d2832f06e4451ac8e38a747a63850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ff4e9209554607911437991178cddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5d5cf02e2849cb9796e041b3ffef57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192ec97243d64bb4876cbaff22e560b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da57de849ee413fade454e337d73e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5176c31891c74114906c43f08b5d4aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# read in safe prompts\n",
    "df = pd.read_csv(\"/kaggle/input/xstest-prompts/xstest_prompts.csv\") # dataset: xstest by Paul RÃ¶ttger: https://aclanthology.org/2024.naacl-long.301/\n",
    "df=df[df[\"label\"]==\"safe\"] # we take the safe subset of XSTest. The original dataset contains both safe and unsafe queries as contrast, but we only need the safe subset. \n",
    "prompts_to_translate = df[\"prompt\"].tolist()\n",
    "\n",
    "# translation pipe \n",
    "pipe = pipeline(\"translation\", model=\"facebook/nllb-200-1.3B\")\n",
    "\n",
    "target_langs = [\"zho_Hans\",\"ben_Beng\",\"deu_Latn\"] # \"zho_Hans\" is simplified Chinese (as opposed to traditional)\n",
    "\n",
    "def translate(texts:list, target_lang):\n",
    "    \"\"\"Translate a list of prompts to a target language.\"\"\"\n",
    "    translated_text = pipe(texts, src_lang=\"eng_Latn\", tgt_lang=target_lang)\n",
    "    return translated_text   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T20:32:33.771082Z",
     "iopub.status.busy": "2025-06-22T20:32:33.770843Z",
     "iopub.status.idle": "2025-06-22T20:36:49.128081Z",
     "shell.execute_reply": "2025-06-22T20:36:49.127435Z",
     "shell.execute_reply.started": "2025-06-22T20:32:33.771066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# run and save to json\n",
    "translations = {}\n",
    "\n",
    "for lang in target_langs: \n",
    "    lang_translation = translate(prompts_to_translate,lang)\n",
    "    translations[lang] = lang_translation\n",
    "\n",
    "with open('/kaggle/working/translations.json', 'w', encoding='utf-8') as f: # this is made to be used in Kaggle, change outputs if running somewhere else obv. \n",
    "    json.dump(translations, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Translations saved to /kaggle/working/translations.json\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7718377,
     "sourceId": 12249607,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
